{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyUSID as usid\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze image data in h5 files to collect histograms\n",
    "\n",
    "* The atoms have been found and separated into sub lattices using Stephen's method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Mo and Re positions for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to lock file, errno = 35, error message = 'Resource temporarily unavailable')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c9212568c85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mh5_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mh5_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0matom_pos_grp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mh5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Measurement_000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel_000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Atom_Positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'w-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to lock file, errno = 35, error message = 'Resource temporarily unavailable')"
     ]
    }
   ],
   "source": [
    "# select relevant atomic coordinates for further analysis\n",
    "# different files store different atoms in centroids_1 and centroids_2 -> sort this out\n",
    "names = ['re05', 're55', 're78', 're95'] # hdf5 file name roots\n",
    "\n",
    "metal_atoms = []\n",
    "intensities = []\n",
    "\n",
    "for name in names:\n",
    "    h5_name = os.path.join(data_dir, name +'.h5')\n",
    "    \n",
    "    h5_file = h5py.File(h5_name, 'r+')\n",
    "    \n",
    "    atom_pos_grp= h5_file['Measurement_000']['Channel_000']['Atom_Positions']\n",
    "    atom_centroids_1 = atom_pos_grp['Atom_Centroids_1']\n",
    "    atom_centroids_2 = atom_pos_grp['Atom_Centroids_2']\n",
    "    cropped_image = atom_pos_grp['Cropped_Image'][:]\n",
    "    \n",
    "    # metal atoms stored only in atom_centroids_1?\n",
    "    if name in ['re05', 're55']:\n",
    "        atoms = atom_centroids_1\n",
    "    else:\n",
    "        atoms = np.vstack((atom_centroids_1, atom_centroids_2))\n",
    "        \n",
    "    metal_atoms.append(atoms)\n",
    "    intensities.append(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate atoms to Mo and Re based on image-specific intensity threshold\n",
    "thresh = [0.80, 0.45, 0.45, 0.45] # intensity thresholds\n",
    "\n",
    "# store types of atoms\n",
    "atom_pos = []\n",
    "atom_ids = []\n",
    "\n",
    "for atoms, intensity, thrs in zip(metal_atoms, intensities, thresh):\n",
    "\n",
    "    Re_atoms = []\n",
    "    Mo_atoms = []\n",
    "\n",
    "    for i in range(atoms.shape[0]):\n",
    "        x, y = atoms[i,:]\n",
    "\n",
    "        if intensity[int(x), int(y)] >= thrs:\n",
    "            Re_atoms.append((x, y))\n",
    "        else:\n",
    "            Mo_atoms.append((x,y))\n",
    "    \n",
    "    Mo_atoms = np.array(Mo_atoms)\n",
    "    Re_atoms = np.array(Re_atoms)\n",
    "\n",
    "    all_atoms = np.vstack((Mo_atoms[:], Re_atoms[:])) #ignoring the sulfur atoms for now.\n",
    "    \n",
    "    all_atoms_ids = np.zeros(all_atoms.shape[0], dtype=int)\n",
    "    all_atoms_ids[:Mo_atoms.shape[0]] = 0 #0 = Mo\n",
    "    all_atoms_ids[Mo_atoms.shape[0]:] = 1 #1 = Re\n",
    "    \n",
    "    atom_pos.append(all_atoms)\n",
    "    atom_ids.append(all_atoms_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot all images with indicated Mo and Re atoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10), dpi = 96)\n",
    "\n",
    "for i, (name, img, apos, aids) in enumerate(zip(names, intensities, atom_pos, atom_ids)):\n",
    "    ir, ic = divmod(i, 2)\n",
    "    axs[ir, ic].imshow(img)#, cmap = 'hot')\n",
    "    axs[ir, ic].scatter(apos[aids==0,1], apos[aids==0,0], c = 'r', s = 2)\n",
    "    axs[ir, ic].scatter(apos[aids==1,1], apos[aids==1,0], c = 'k', s = 2)\n",
    "    axs[ir, ic].get_xaxis().set_visible(False)\n",
    "    axs[ir, ic].get_yaxis().set_visible(False)\n",
    "    axs[ir, ic].set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to calculate atom-atom distances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_calc(pt, pts):\n",
    "    \"\"\"Distance between a point 'pt' and a list of points 'pts'\"\"\"\n",
    "    \n",
    "    distances = []\n",
    "    for ind in range(pts.shape[0]):\n",
    "        distances.append((np.sqrt((pt[0] - pts[ind,0])**2 + (pt[1] - pts[ind,1])**2), ind))\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make hexagon neighbor configuration more regular for further analysis of pair relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hexagon(pos):\n",
    "    \"\"\"\n",
    "    Scale neighbor positions so that they have the same distance from their center of mass.\n",
    "    \"\"\"\n",
    "    \n",
    "    com_x = sum([p[0] for p in pos])/len(pos)\n",
    "    com_y = sum([p[1] for p in pos])/len(pos)\n",
    "    \n",
    "    pos_hex = []\n",
    "    for p in pos:\n",
    "        dx = p[0] - com_x\n",
    "        dy = p[1] - com_y\n",
    "        r = (dx*dx + dy*dy)**0.5\n",
    "        pos_hex.append([dx/r, dy/r])\n",
    "    \n",
    "    return pos_hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration classification function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(pos, ids):\n",
    "    \"\"\"\n",
    "    Assign unique identifiers to the neighbor configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    # scale to make the neighbor hexagon more regular\n",
    "    pos = hexagon(pos)\n",
    "    \n",
    "    # collect pair distances between neighbors and add the pair type (0, 1, 2)\n",
    "    pair_list = []\n",
    "    for i in range(len(pos)):\n",
    "        for j in range(i+1, len(pos)):\n",
    "            r = np.sqrt((pos[i][0]-pos[j][0])**2 + (pos[i][1]-pos[j][1])**2)\n",
    "            pair_list.append((r, ids[i]+ids[j]))\n",
    "    \n",
    "    assert len(pair_list) == 15, f'Wrong number of pair distances: {len(pair_list)}'\n",
    "    \n",
    "    # number of Re atoms in the neighbor list\n",
    "    n_atom = sum([1 for elem in ids if elem == 1])\n",
    "    \n",
    "    # sort the pair list according to distances\n",
    "    pair_list = sorted(pair_list, key=lambda x: x[0])\n",
    "    \n",
    "    # number of Re-Re pairs among the 6 shortest distances distances (ortho)\n",
    "    n_ortho = sum([1 for elem in pair_list[0:6] if elem[1] == 2])\n",
    "    \n",
    "    # number of Re-Re pairs among the 6 medium distances distances (meta)\n",
    "    n_meta = sum([1 for elem in pair_list[6:12] if elem[1] == 2])\n",
    "    \n",
    "    # number of Re-Re pairs among the 3 longest distances distances (para)\n",
    "    n_para = sum([1 for elem in pair_list[12:15] if elem[1] == 2])\n",
    "\n",
    "    return [n_atom, n_ortho, n_meta, n_para]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collect histograms of all possible configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Image specific distance thresholds\n",
    "dist_thres = [45, 32, 30, 26]\n",
    "\n",
    "target_hist = {}\n",
    "\n",
    "# cycle over lists of atoms from different images\n",
    "for name, apos, aids, dthres in zip(names, atom_pos, atom_ids, dist_thres):\n",
    "\n",
    "    configs = []\n",
    "    \n",
    "    # for each atom, find its neighbors, center it\n",
    "    for i, (c_pos, c_id) in enumerate(zip(apos, aids)):\n",
    "        \n",
    "        x, y = c_pos\n",
    "        distances = dist_calc([x, y], apos)\n",
    "\n",
    "        neighbor_i = []\n",
    "        neighbor_pos = []\n",
    "        neighbor_id = []\n",
    "        for k in range(len(distances)):\n",
    "            if distances[k][0] <= dthres and distances[k][0] > 0:\n",
    "                j = distances[k][1]\n",
    "                neighbor_i.append(j)\n",
    "                neighbor_pos.append(apos[j])\n",
    "                neighbor_id.append(aids[j])\n",
    "        \n",
    "        if len(neighbor_i) < 6:\n",
    "            continue\n",
    "            \n",
    "        assert len(neighbor_i) == 6, f\"Incorrect number of neighbors: {len(neighbor_i)}, {name}\"\n",
    "        \n",
    "        # classify configurations - assign unique ids based on counts of ortho, meta, and para distances\n",
    "        configs.append(tuple([c_id] + classify(neighbor_pos, neighbor_id)))\n",
    "            \n",
    "    # get counts of distinct configuraions\n",
    "    counts = Counter(configs)\n",
    "    print('Number of configuration types:', len(counts))\n",
    "    print('Total number of configurations (atoms with 6 neighbors):', sum(counts.values()))#, counts)\n",
    "    target_hist[name] = counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a set of all dictinct configurations found in the four images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_list = [c for h in target_hist.values() for c in h]\n",
    "cfg_types = sorted(set(cfg_list))\n",
    "print('Number of distinct configurations:', len(cfg_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_re = {}\n",
    "for name in names:\n",
    "    re_sum = sum([v for k, v in target_hist[name].items() if k[0]==1])\n",
    "    mo_sum = sum([v for k, v in target_hist[name].items() if k[0]==0])\n",
    "    c = re_sum/(re_sum + mo_sum)\n",
    "    x_re[name] = c\n",
    "\n",
    "print(x_re.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot configuration histograms for different images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi = 96)\n",
    "\n",
    "cfg_labels = [str(c) for c in cfg_types]\n",
    "num_samples = {}\n",
    "for i, name in enumerate(names):\n",
    "    counts = target_hist[name]\n",
    "    all_counts = np.array([counts.get(cfg, 0) for cfg in cfg_types])\n",
    "    n_sample = np.sum(all_counts)\n",
    "    num_samples[name] = n_sample\n",
    "    all_counts = all_counts/float(n_sample)\n",
    "\n",
    "    ir, ic = divmod(i, 2)\n",
    "    axs[ir, ic].bar(cfg_labels, all_counts)\n",
    "    axs[ir, ic].set_xticklabels(cfg_labels, rotation=90.0)\n",
    "    axs[ir, ic].set_title('Image: ' + name + ', Total number of samples: n = ' + str(n_sample))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Assign configuration ID from simulations to ID from image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "# Neighbor hexagon positions\n",
    "neighbor_pos = [\n",
    "    [1.0, 0.0],\n",
    "    [-1.0, 0.0],\n",
    "    [ np.cos(np.pi/3.0),  np.sin(np.pi/3.0)],\n",
    "    [-np.cos(np.pi/3.0),  np.sin(np.pi/3.0)],\n",
    "    [ np.cos(np.pi/3.0), -np.sin(np.pi/3.0)],\n",
    "    [-np.cos(np.pi/3.0), -np.sin(np.pi/3.0)],\n",
    "]\n",
    "\n",
    "conf_dict = {}\n",
    "\n",
    "i = 0\n",
    "for c_id in range(2): # pick center atom type                                           \n",
    "    dx = c_id                                                                           \n",
    "    for neighbor_id in product((0, 1), repeat=6):\n",
    "\n",
    "        conf_id = tuple([c_id] + classify(neighbor_pos, neighbor_id))\n",
    "            \n",
    "        i += 1                                                      \n",
    "        conf_dict[i] = conf_id\n",
    "\n",
    "conf_counts = Counter(conf_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random configuration probabilities\n",
    "\n",
    "ntot = 7 # number of atoms in the configuration\n",
    "\n",
    "prob_conf = {}\n",
    "for name in names:\n",
    "    x = x_re[name]\n",
    "    p_c = {}\n",
    "    for k, v in conf_counts.items():\n",
    "        \n",
    "        # number of Re atoms in the configuration\n",
    "        n_re = k[0] + k[1]\n",
    "        \n",
    "        #probability of a configuration with n_re atoms\n",
    "        prob = x**n_re * (1.0-x)**(ntot - n_re)\n",
    "        \n",
    "        # weight probability by symmetry numbers (v)\n",
    "        p_c[k] = prob*v\n",
    "            \n",
    "    prob_conf[name] = p_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi = 96)\n",
    "\n",
    "cfg_labels = [str(c) for c in cfg_types]\n",
    "for i, name in enumerate(names):\n",
    "    counts = target_hist[name]\n",
    "    p_conf = prob_conf[name]\n",
    "    all_counts = np.array([counts.get(cfg, 0) for cfg in cfg_types])\n",
    "    n_sample = np.sum(all_counts)\n",
    "    all_counts = all_counts/float(n_sample)\n",
    "\n",
    "    p_array = [(k, v) for k, v in p_conf.items()]\n",
    "    #cft_labels = [str(k[0]) for k in p_array]\n",
    "    #all_counts_p = [float(k[1]) for k in p_array]\n",
    "    all_counts_p = np.array([prob_conf[name].get(cfg, 0) for cfg in cfg_types])\n",
    "\n",
    "    \n",
    "    nconf = len(cfg_labels)\n",
    "    width = 0.4\n",
    "\n",
    "    ir, ic = divmod(i, 2)\n",
    "    axs[ir, ic].bar(np.arange(nconf)-0.2, all_counts, width, color='b')\n",
    "    axs[ir, ic].bar(np.arange(nconf)+0.2, all_counts_p, width, color='r')\n",
    "    axs[ir, ic].set_xticks(range(nconf))\n",
    "    axs[ir, ic].set_xticklabels(cfg_labels, rotation=90.0)\n",
    "    axs[ir, ic].set_title('Image: ' + name + '\\nActual Re concentration: ' + str(x_re[name]))#', Total number of samples: n = ' + str(n_sample))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../../force_fields/statmechlib')\n",
    "from statmechlib.read_write import read_lattice_model, read_modeldef, write_modeldef\n",
    "from statmechlib.preprocessing import get_stats_latt \n",
    "from statmechlib.forcefields import sd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_dir = '../src/code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read reference system parameters into an array\n",
    "pars_ref = {}\n",
    "for name in names:\n",
    "    data_path = os.path.join(sim_dir, name)\n",
    "    params = read_modeldef(os.path.join(data_path, 'lg.mld'))\n",
    "    pars_ref[name] = np.array([v for v in params['ref_params'].values()]).flatten(order='F')\n",
    "\n",
    "assert len(set([str(v) for v in pars_ref.values()])) == 1, \"Different parameters\"\n",
    "\n",
    "pars_ref = pars_ref[names[0]]\n",
    "pars_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lattice simulation results: configuration statistics and energies\n",
    "trjs = {}\n",
    "for name in names:\n",
    "    data_path = os.path.join(sim_dir, name)\n",
    "    trjs[name] = read_lattice_model(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make transformation matrix from old to new histogram\n",
    "trans_hist = {}\n",
    "conf_list = sorted(list(set(conf_dict.values()))) # row index\n",
    "nrows = len(conf_list) \n",
    "ncols = len(conf_dict)\n",
    "print(nrows, ncols)\n",
    "\n",
    "trans_hist = np.zeros((nrows, ncols), dtype=float)\n",
    "for key, val in conf_dict.items():\n",
    "    # find index for the first occurence of the value\n",
    "    #row = [i for i, e in enumerate(conf_list) if e == val][0]\n",
    "    row = conf_list.index(val)\n",
    "    col = key - 1\n",
    "    trans_hist[row, col] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group symmetric configurations based on their unique label\n",
    "hsv = {}\n",
    "hsv_ave = {}\n",
    "for name in names:\n",
    "    old_hist = np.array(trjs[name]['config_stats'])\n",
    "    hsv[name] = trans_hist.dot(old_hist.T).T\n",
    "    for i in range(hsv[name].shape[0]):\n",
    "        sm = np.sum(hsv[name][i,:])\n",
    "        hsv[name][i,:] = hsv[name][i,:]/sm\n",
    "    \n",
    "    histave = []\n",
    "    for i in range(hsv[name].shape[1]):\n",
    "        histave.append(sum(hsv[name][:,i])/float(hsv[name].shape[0]))\n",
    "    hsv_ave[name] = np.array(histave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the results (discard initial configurations)\n",
    "hsu = {}\n",
    "for name in names:\n",
    "    hsu[name] = np.array([np.array(ar).flatten(order='F') for ar in trjs[name]['interaction_stats']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the results (discard initial configurations)\n",
    "imin = 10\n",
    "for name in names:\n",
    "    hsv[name] = hsv[name][imin:,:]\n",
    "    hsu[name] = hsu[name][imin:,:]\n",
    "    trjs[name]['energy'] = trjs[name]['energy'][imin:]\n",
    "    trjs[name]['temp'] = trjs[name]['temp'][imin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trjs['re05']['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare simulated statistics with target and random histograms\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), dpi = 96)\n",
    "\n",
    "cfg_labels = [str(c) for c in cfg_types]\n",
    "gsv = {}\n",
    "for i, name in enumerate(names):\n",
    "    counts = target_hist[name]\n",
    "    #p_conf = prob_conf[name]\n",
    "    all_counts = np.array([counts.get(cfg, 0) for cfg in cfg_types])\n",
    "    n_sample = np.sum(all_counts)\n",
    "    all_counts = all_counts/float(n_sample)\n",
    "    gsv[name] = all_counts\n",
    "    all_counts_p = np.array([prob_conf[name].get(cfg, 0) for cfg in cfg_types])\n",
    "\n",
    "    nconf = len(cfg_labels)\n",
    "    width = 0.2\n",
    "\n",
    "    ir, ic = divmod(i, 2)\n",
    "    axs[ir, ic].bar(np.arange(nconf)-0.2, np.sqrt(all_counts), width, color='b')\n",
    "    axs[ir, ic].bar(np.arange(nconf)+0.0, np.sqrt(all_counts_p), width, color='r')\n",
    "    axs[ir, ic].bar(np.arange(nconf)+0.2, np.sqrt(hsv_ave[name]), width, color='y')\n",
    "    axs[ir, ic].set_xticks(range(nconf))\n",
    "    axs[ir, ic].set_xticklabels(cfg_labels, rotation=90.0)\n",
    "    axs[ir, ic].set_title('Image: ' + name)# + ', Total number of samples: n = ' + str(n_sample))\n",
    "    axs[ir, ic].set_xlabel('configuration ID')\n",
    "    axs[ir, ic].set_ylabel(r'$\\sqrt{p}$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assemble target and reference data structures\n",
    "targets = {}\n",
    "stats = {}\n",
    "for name in names:\n",
    "    # target\n",
    "    targ = {}\n",
    "    targ['config_stats'] = gsv[name]\n",
    "    targ['weight'] = num_samples[name]/sum(num_samples.values())\n",
    "    targets[name] = targ\n",
    "    \n",
    "    # reference data\n",
    "    stat = {}\n",
    "    stat['config_stats'] = hsv[name]\n",
    "    stat['interaction_stats'] = hsu[name]\n",
    "    stat['energy'] = np.array(trjs[name]['energy'])\n",
    "    stat['temp'] = np.array(trjs[name]['temp'])\n",
    "    stats[name] = stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_in = np.array([pars_ref[1], pars_ref[2], pars_ref[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin\n",
    "\n",
    "print('# Start sd2 =', sd2(pars_in, stats, targets))\n",
    "print('# Starting parameters:', pars_in)\n",
    "output = fmin(sd2, pars_in, args=(stats, targets), maxiter=100000, maxfun=10000, disp=0, full_output=1)\n",
    "print('\\n# End sd2 =', output[1])\n",
    "p_out = output[0]\n",
    "print('# Final parameters:', p_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new parameters\n",
    "pars = [0., p_out[0], 0., 0., p_out[1], 0.]\n",
    "\n",
    "# write model definition file into a simulation directory\n",
    "for name in names:\n",
    "    data_path = os.path.join(sim_dir, name)\n",
    "    print(os.path.join(data_path, 'lg.mld'))\n",
    "    write_modeldef(os.path.join(data_path, 'lg.mld'), pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run simulations and wait until they are complete\n",
    "\n",
    "#from subprocess import Popen, PIPE\n",
    "\n",
    "#f_list = glob.glob('./*bz2')\n",
    "#cmds_list = [['./bunzip2_file.py', file_name] for file_name in f_list]\n",
    "#procs_list = [Popen(cmd, stdout=PIPE, stderr=PIPE) for cmd in cmds_list]\n",
    "\n",
    "#original_dir = os.getcwd()\n",
    "\n",
    "#os.chdir(sim_dir)\n",
    "\n",
    "#proc_list = []\n",
    "#for name in names:\n",
    "    \n",
    "#    os.chdir('./'+name)\n",
    "#    cmd = './lg < ' + name + '.inp > lg.run'\n",
    "#    proc_list.append(Popen(cmd, stdout=PIPE, stderr=PIPE))\n",
    "#    os.chdir('..')\n",
    "\n",
    "#for proc in procs_list:\n",
    "#    proc.wait()\n",
    "\n",
    "#os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.07051797 -0.27910435\n",
    "\n",
    "0.02054406 -0.50064873\n",
    "\n",
    "0.06463121 -0.22251215 0.018662095932150156\n",
    "\n",
    "0.02972088 -0.30352361 0.018200443606690948\n",
    "\n",
    "0.10573289 -0.45494785 0.01816080620437813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![re05](\"../reports/r05.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "print('Re05')\n",
    "Image(\"../reports/r05.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Re55')\n",
    "Image(\"../reports/r55.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Re78')\n",
    "Image(\"../reports/r78.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Re95')\n",
    "Image(\"../reports/r95.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
